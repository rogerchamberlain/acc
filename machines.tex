\section{Machines}
\label{sec:machines}

After the initial set of machines described in the previous section,
a number of additional machines have been designed, built, and deployed
that support multiple accelerators.

In 2012, the Chimera system was described~\cite{ibs12}.
It combined Intel multicores, NVIDIA Tesla C2070 graphics engines,
and an Altera (now Intel) Stratix-IV reconfigurable logic card using
the motherboard's PCIe bus. The authors describe approaches to deploying
a variety of applications on the system. However, performance results
are not provided.

A multiple accelerator cluster built at the Center for Development of
Advanced Computing (C-DAC) in Bangalore, India, was described in
2014~\cite{admb14}. Here, the authors adapted the StarPU development
environment~\cite{starpu} to support reconfigurable logic as well as
simultaneous support of CUDA and OpenCL in the same application.
A Monte Carlo simulation application is described, achieving a 22$\times$
speedup relative to a Xeon processor.

Also in 2014, Wu et al.~\cite{whk+14} describe a heterogeneous compute
platform that has multicores, graphics engines, and reconfigurable logic
that has a focus on power efficient computing.
The authors explore four application examples, but similar to the QP
machine, chose to exploit one accelerator type or another, but not both
simultaneously.

Proa\~no et al.~\cite{pcc14} describe an open-source framework for
integrating accelerators into a cloud infrastructure.  Their goal is
to enable both graphics engines and reconfigurable logic as compute resources
in the Infrastructure as a Service (IaaS) cloud service model.
With AWS having already announced the availability of graphics engines
in the cloud, the authors focused on exploring the issues associated
with enabling the reconfigurable logic.

In 2015, Rethinagiri et al.~\cite{rpm+15} described a pair of computational
platforms that included both graphics engines and reconfigurable logic.  One
was targeting high-performance computing (HPC) applications and the other
was targeting high-performance embedded (HPE) applications.
In both cases, their interest was a combination of performance and
energy efficiency. Table~\ref{tbl:hpchpe} gives the particulars of
the two platforms (extracted from Table~I of~\cite{rpm+15}).

\begin{table}[ht]
\centering
\caption{Specifications for HPC and HPE platforms~\protect\cite{rpm+15}.}
\label{tbl:hpchpe}
\vspace{0.1in}
\begin{tabular}{c | c | c | c}
Domain & Engine & Specification & Communication \\ \hline
\multirow{3}{*}{HPC} & cores & Intel Xeon E5-2634 & Gen3 $\times$16 \\ \cline{2-4}
 & GPU & NVIDIA Telsa K40 & Gen3 $\times$16 \\ \cline{2-4}
 & FPGA & Xilinx Virtex-7 VC709 & Gen3 $\times$8 \\ \hline
\multirow{2}{*}{HPE} & cores and GPU & NVIDIA Jetson TK1 & Gen2 $\times$1 \\ \cline{2-4}
 & cores and FPGA & Xilinx Zynq-7015 & Gen2 $\times$4
\end{tabular}
\end{table}

The authors give performance results and energy efficiency for five
applications across the pair of machines:
computed tomography, face recognition, video coding, character recognition,
and motion tracking.

Segal and Margala~\cite{sm16} describe a system contructed using commodity cloud
nodes (from AWS) and a locally deployed node containing a reconfigurable logic
card.  They used the SparkCL framework~\cite{sparkcl}, which adds accelerator
support to Apache Spark, to deploy an N-body simulation. They conclude that
which accelerator gives the best performance depends in part on the dynamics
of the particle interactions in the N-body simulation.
