\section{Applications}
\label{sec:apps}

The vast majority of the applications that have been deployed on
more than one accelerator have combined graphics engines and reconfigurable
logic as the two types of accelerator.
Table~\ref{tbl:apps} summarizes the literature for these applications,
indicating the application itself, the year of publication (including
the citation), and various notes about the specific implementation.
Particularly, for each application it is indicated whether (or not)
the application assigns distinct functions to the two different
accelerator types, and also whether (or not) the map-reduce programming
model is used as part of the implementation.

%FPGA and GPU:
%nano sim~\cite{khdo06},
%MC sim~\cite{shsc08,tttl10},
%n-body sim~\cite{tl10},
%crypto~\cite{dfg+13},
%vision~\cite{bkdb10,ghgb11,brf14},
%astronomy (and discussion of dwarfs)~\cite{ibs12},
%astronomy (embedded in instrument)~\cite{kgb+14},
%cardiac optical mapping~\cite{mjk12},
%medical imaging~\cite{szb+12,sll13},
%image processing~\cite{dbd+13}.
%toy MC sim~\cite{admb14},
%BLASTp~\cite{Papad14},
%combo HPC and embedded~\cite{rpm+15},
%image processing in embedded application~\cite{enr+18,nsg+16,zxl+18},
%data acquisition in science~\cite{cab+17,vac+16},
%GWAS~\cite{kws+16},
%GWIS~\cite{wkhe17},
%driver assistance~\cite{wlhk17}
%gene-gene interactions~\cite{wkhe18},

\begin{table}[htp]
\centering
\caption{Applications deployed on multiple accelerators.}
\label{tbl:apps}
\vspace{0.1in}
\begin{tabular}{p{0.15\linewidth} | c | c | p{0.6\linewidth}}
Application & Ref. & Year & Notes \\ \hline
EM sim & \cite{kdh+06} & 2006 & First known example$^*$ \\ \hline
\multirow{4}{\linewidth}{Monte Carlo simulation} & \cite{ytt+08} & 2008 & European options pricing$^\dag$  \\ \cline{2-4}
 & \cite{shsc08} & 2008 & Financial value-at-risk computation$^*$  \\ \cline{2-4}
 & \cite{tttl10} & 2010 & Asian options and generalized asset pricing \\ \cline{2-4}
 & \cite{admb14} & 2014 & Computation of $\pi$$^*$ \\ \hline
\multirow{3}{\linewidth}{N-body simulation} & \cite{ytt+08} & 2008 & Dynamic workload distribution$^\dag$ \\ \cline{2-4}
 & \cite{tl10} & 2010 & Introduced Axel cluster$^\dag$ \\ \cline{2-4}
 & \cite{sm16} & 2016 & AWS GPUS plus local FPGA \\ \hline
\multirow{2}{\linewidth}{crypto} & \cite{ytt+08} & 2008 & Brute force key search$^\dag$ \\ \cline{2-4}
 & \cite{dfg+13} & 2013 & Password search for PDF documents$^*$ \\ \hline
\multirow{2}{\linewidth}{machine learning} & \cite{bkdb10} & 2010 & Pedestrian detection$^*$ \\ \cline{2-4}
 & \cite{log+18} & 2018 & Character recognition$^*$ \\ \hline
\multirow{2}{*}{vision} & \cite{ghgb11} & 2011 & Stereo 3D video production$^*$ \\ \cline{2-4}
 & \cite{brf14} & 2014 & Hand tracking$^*$ \\ \hline
\multirow{5}{\linewidth}{medical imaging} & \cite{szb+12} & 2012 & Includes both static and dynamic assignment$^*$ \\ \cline{2-4}
 & \cite{mjk12} & 2012 & Cardiac mapping \\ \cline{2-4}
 & \cite{sll13} & 2013 & Transmural electrophysiological imaging$^*$ \\ \cline{2-4}
 & \cite{rpm+15} & 2015 & Cone beam computed tomography$^*$ \\ \cline{2-4}
 & \cite{cwl18} & 2018 & Ultrasonic imaging$^*$ \\ \hline
\multirow{5}{\linewidth}{image processing} & \cite{dbd+13} & 2013 & Pedestrian recognition$^*$ \\ \cline{2-4}
 & \cite{rpm+15} & 2015 & Face recognition and character recognition$^*$ \\ \cline{2-4}
 & \cite{nsg+16} & 2016 & Data acquisition for experimental physics$^*$ \\ \cline{2-4}
 & \cite{enr+18} & 2018 & Add dynamic function distribution to above$^*$\\ \cline{2-4}
 & \cite{zxl+18} & 2018 & Increase frame rate to 9000 frames/s$^*$ \\ \hline
astronomy & \cite{kgb+14} & 2014 & Radio antenna cross-correlation$^*$ \\ \hline
\multirow{4}{\linewidth}{comp bio} & \cite{Papad14} & 2014 & Protein-protein sequence alignment$^*$ \\ \cline{2-4}
 & \cite{kws+16} & 2016 & Genome-wide association studies$^*$ \\ \cline{2-4}
 & \cite{wkhe17} & 2017 & Genome-wide interaction studies$^*$ \\ \cline{2-4}
 & \cite{wkhe19} & 2019 & Computation of gene-gene interactions$^*$ \\ \hline
video & \cite{rpm+15} & 2015 & Video coding and motion tracking$^*$ \\ \hline
\multirow{4}{\linewidth}{data acquisition} & \cite{vac+16} & 2016 & Linear accelerator$^*$ \\ \cline{2-4}
 & \cite{cab+17} & 2017 & Trigger systems for Large Hadron Collider$^*$ \\ \cline{2-4}
 & \cite{hzlw18} & 2018 & 3D waveform oscilloscope \\ \cline{2-4}
 & \cite{crk+19} & 2019 & Linear accelerator$^*$ \\ \hline
\multirow{2}{\linewidth}{driving} & \cite{wlhk17} & 2017 & Driver assistance (lane detection) \\ \cline{2-4}
 & \cite{lzh+18} & 2018 & Autonomous vehicle computations$^*$ \\ \hline
\end{tabular}
$^*$Assigns distinct functions to the two accelerators. $^\dag$Utilizes map-reduce.
\end{table}

An example of partitioning the workload based on the distinct functions to be
performed is described by Danczul et al.~\cite{dfg+13}. The authors are
attempting a brute force attack on the password for a set of PDF encrypted
files.  This requires both MD5 hash computations as well as RC4 stream cypher 
computations.  They assign the MD5 hashes to the graphics engines, in part
due to its limited memory requirements, and assign the RC4 computations to the
reconfigurable logic (in which the memory requirements of the RC4 algorithm
can be accommodated efficiently).

In a large fraction of the implementations where the workload is
divided by function onto each accelerator, the computation is 
organized as a pipeline.  Data flows into one accelerator, the portion
of the work assigned to that accelerator is performed, the output
of that pipeline stage then flows into the other accelerator, where
the portion of the work assigned to that accelerator is performed.

Sb\^{\i}rlea et al.~\cite{szb+12} extend this to general dataflow graphs,
supporting a richer set of topologies than just a simple pipeline.  The authors
also incorporate the ability to support a work stealing scheduler across
execution platforms.

A clear benefit of the map-reduce paradigm is that it is relatively
straightforward to express the computational parallelism available in
an algorithm using this approach.  Several applications took advantage
of this.  In addition, it can also support the dynamic assignment of
workload across the available computational resources, illustrated as
early as 2008 by Yeung et al.~\cite{ytt+08}.

For the set of Monte Carlo simulations listed in the table,
four of the five problems attempted
(\cite{tttl10} includes two) are some form of financial computation.
This hints at the strong interest in accelerated computation on the
part of the financial industry.

Any time multiple compute resources are used in an application, there is
the potential for data movement between those resources to be a performance
bottleneck.  Bittner et al.~\cite{brf14} demonstrate direct graphics engine
to reconfigurable logic DMA data transfers over PCIe, avoiding a copy
to/from the host memory.
Ammendola et al.~\cite{abb+13} also exploit a combination of FPGAs and
graphics engines; however, the FPGAs are not used for application functionality
but instead are used to implement GPU to GPU communications.

In the past decade, there has been a continuation of the research that
seeks to compare one accelerator type with another. Examples of this
that compare reconfigurable logic with graphics engines include:
scientific computations~\cite{wghp11},
compressed sensing and Cholesky decomposition~\cite{ypl12},
sliding-window computations~\cite{cfbs15},
microscopy~\cite{tzwz15},
de novo assembly (in computational biology)~\cite{mjk+16},
erasure coding~\cite{czs+16},
database join~\cite{rl17},
and data integration~\cite{fcb+19}.
Caraba\~no et al.~\cite{cdde13} compare
energy efficiency, performance, and productivity across accelerators, and
V\'{e}stias and Neto~\cite{vn14} explore accelerator trends, particularly
as they impact both peak performance and sustained performance.
O'Neal and Brisk~\cite{ob18} provide predictive models for each of the
constituent
computational engines: multicores, graphics engines, and reconfigurable
logic, quantifying both performance and power consumption.

A number of investigations have concluded that which accelerator
is preferred often depends upon the properties of the input data.
Examples of applications for which this is true include:
linear algebra~\cite{gchg16,sll+13},
sparse matrix multiplication~\cite{gsbh16},
and vision~\cite{mfo+16}.
In general, the conclusions drawn in the previous decade (see
Section~\ref{sec:compare}) still hold for this work as well.

Graphics engines and reconfigurable logic are not the only accelerators
available, however.  More recent investigations that have included the Cell in
the mix include biological sequence alignment~\cite{bal+12}.
Work comparing the Cell with graphics engines (but not including
reconfigurable logic) includes
wavelet transforms~\cite{bck+11},
Bayesian analysis in bioinformatics~\cite{pts+12},
molecular dynamics~\cite{pts+12}, and the TPC decision support
benchmark~\cite{pts+12}.

Research that compares graphics engines, reconfigurable logic and
the Xeon Phi include an investigation of
sparse matrix multiplication~\cite{gsbh16} as well as the development of
predictive models for power and energy for all three
execution platforms~\cite{opr+17}.
Dropping reconfigurable logic from the comparison yields the following
application investigations:
Ising model simulation~\cite{ws13},
microscopy~\cite{tkk+14},
quantum chemistry~\cite{lrg14},
quantum many-body simulations~\cite{Lyakh15}, and
Jacobi relaxation~\cite{cv16}.
Productivity, performance, and energy quantification is pursued
by Memeti et al.~\cite{mlp+17}.

We next turn our focus away from individual applications, and focus
instead on the development environments that enable these applications
to be designed, implemented, deployed, tested, and executed.
